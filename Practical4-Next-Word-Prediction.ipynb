{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_bB0srzceP9p"
      },
      "outputs": [],
      "source": [
        "# Preamble\n",
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of the text file containing the training data\n",
        "training_data_file = '/content/eminem_songs_lyrics.txt'"
      ],
      "metadata": {
        "id": "dd2_TbH7fTXu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(sentence):\n",
        "    return sentence.translate(str.maketrans('','', string.punctuation))"
      ],
      "metadata": {
        "id": "DKTA0S3EfTUq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add2dict(dictionary, key, value):\n",
        "    if key not in dictionary:\n",
        "        dictionary[key] = []\n",
        "    dictionary[key].append(value)"
      ],
      "metadata": {
        "id": "ZHzB-gKXfTN1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list2probabilitydict(given_list):\n",
        "    probability_dict = {}\n",
        "    given_list_length = len(given_list)\n",
        "    for item in given_list:\n",
        "        probability_dict[item] = probability_dict.get(item, 0) + 1\n",
        "    for key, value in probability_dict.items():\n",
        "        probability_dict[key] = value / given_list_length\n",
        "    return probability_dict"
      ],
      "metadata": {
        "id": "Gcu_Y2NZfTLJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_word = {}\n",
        "second_word = {}\n",
        "transitions = {}"
      ],
      "metadata": {
        "id": "qleeBaFqfTIG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains a Markov model based on the data in training_data_file\n",
        "def train_markov_model():\n",
        "    for line in open(training_data_file):\n",
        "        tokens = remove_punctuation(line.rstrip().lower()).split()\n",
        "        tokens_length = len(tokens)\n",
        "        for i in range(tokens_length):\n",
        "            token = tokens[i]\n",
        "            if i == 0:\n",
        "                initial_word[token] = initial_word.get(token, 0) + 1\n",
        "            else:\n",
        "                prev_token = tokens[i - 1]\n",
        "                if i == tokens_length - 1:\n",
        "                    add2dict(transitions, (prev_token, token), 'END')\n",
        "                if i == 1:\n",
        "                    add2dict(second_word, prev_token, token)\n",
        "                else:\n",
        "                    prev_prev_token = tokens[i - 2]\n",
        "                    add2dict(transitions, (prev_prev_token, prev_token), token)\n",
        "\n",
        "    # Normalize the distributions\n",
        "    initial_word_total = sum(initial_word.values())\n",
        "    for key, value in initial_word.items():\n",
        "        initial_word[key] = value / initial_word_total\n",
        "\n",
        "    for prev_word, next_word_list in second_word.items():\n",
        "        second_word[prev_word] = list2probabilitydict(next_word_list)\n",
        "\n",
        "    for word_pair, next_word_list in transitions.items():\n",
        "        transitions[word_pair] = list2probabilitydict(next_word_list)\n",
        "\n",
        "    print('Training successful.')"
      ],
      "metadata": {
        "id": "lxq0F4ThfTFA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_markov_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL-oRhp6fTCU",
        "outputId": "8d8eea3c-e170-4b31-b98b-37b7fe603a65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_word(dictionary):\n",
        "    p0 = np.random.random()\n",
        "    cumulative = 0\n",
        "    for key, value in dictionary.items():\n",
        "        cumulative += value\n",
        "        if p0 < cumulative:\n",
        "            return key\n",
        "    assert(False)"
      ],
      "metadata": {
        "id": "-AR4k0xpfS_x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_sentences = 10"
      ],
      "metadata": {
        "id": "3NOw4LxffS9f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate sample text\n",
        "def generate():\n",
        "    for i in range(number_of_sentences):\n",
        "        sentence = []\n",
        "        # Initial word\n",
        "        word0 = sample_word(initial_word)\n",
        "        sentence.append(word0)\n",
        "        # Second word\n",
        "        word1 = sample_word(second_word[word0])\n",
        "        sentence.append(word1)\n",
        "        # Subsequent words untill END\n",
        "        while True:\n",
        "            word2 = sample_word(transitions[(word0, word1)])\n",
        "            if word2 == 'END':\n",
        "                break\n",
        "            sentence.append(word2)\n",
        "            word0 = word1\n",
        "            word1 = word2\n",
        "        print(' '.join(sentence))"
      ],
      "metadata": {
        "id": "dWDtz1T7fSsm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvYu3JqwfSUB",
        "outputId": "ab89e29c-5469-4ce7-c68e-2c9ab5558dcd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amoxacillin is just not real enough\n",
            "lonely roads god only knows\n",
            "with fucking cornrows\n",
            "im drunk so satan take the fucking wheel\n",
            "so shes been on the wall of shame\n",
            "im not killing them\n",
            "im an mc still as honest\n",
            "im a human\n",
            "rappers are hungry looking at me like its lunchtime\n",
            "we have nothing in common poodle\n"
          ]
        }
      ]
    }
  ]
}